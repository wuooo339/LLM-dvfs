# LLM DVFS æµ‹è¯•é¡¹ç›®

è¿™ä¸ªé¡¹ç›®ç”¨äºæµ‹è¯•å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¸åŒé˜¶æ®µçš„åŠŸè€—å’Œæ€§èƒ½ï¼Œæ”¯æŒä¼ ç»Ÿå•å®ä¾‹å’Œåˆ†ç¦»å¼ Prefill+Decode ä¸¤ç§æ¶æ„çš„å¯¹æ¯”æµ‹è¯•ã€‚

## ğŸ”¥ å¿«é€Ÿå¼€å§‹ - GPUåŠŸè€—ç›‘æ§å·¥å…·

### å¤šGPUåŠŸè€—ç›‘æ§ (`multi_gpu_monitor.py`)

å®æ—¶ç›‘æ§å¤šä¸ªGPUçš„åŠŸè€—ã€æ¸©åº¦ã€åˆ©ç”¨ç‡ç­‰æ•°æ®ï¼Œæ”¯æŒ100msé«˜ç²¾åº¦é‡‡æ ·ã€‚

#### åŸºæœ¬ä½¿ç”¨

```bash
# ç›‘æ§4ä¸ªGPUï¼ˆé»˜è®¤ï¼‰ï¼Œ100msé—´éš”
python3 multi_gpu_monitor.py

# æŒ‡å®šGPUå’Œé‡‡æ ·é—´éš”
python3 multi_gpu_monitor.py --gpu-ids "0,1,2,3" --interval 0.1

# ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶
python3 multi_gpu_monitor.py --output gpu_power_data.csv

# åŒæ—¶ä¿å­˜CSVå’ŒJSONæ ¼å¼æ•°æ®
python3 multi_gpu_monitor.py --output gpu_power.csv --json gpu_power.json

# å®šæ—¶ç›‘æ§ï¼ˆä¾‹å¦‚ç›‘æ§60ç§’ï¼‰
python3 multi_gpu_monitor.py --duration 60 --output gpu_power_60s.csv
```

#### å‚æ•°è¯´æ˜

- `--gpu-ids`: è¦ç›‘æ§çš„GPU IDåˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼ˆé»˜è®¤: "0,1,2,3"ï¼‰
- `--interval`: é‡‡æ ·é—´éš”ç§’æ•°ï¼ˆé»˜è®¤: 0.1ï¼Œå³100msï¼‰
- `--output`: CSVè¾“å‡ºæ–‡ä»¶è·¯å¾„
- `--json`: JSONè¯¦ç»†æ•°æ®è¾“å‡ºæ–‡ä»¶è·¯å¾„
- `--duration`: ç›‘æ§æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œä¸æŒ‡å®šåˆ™æŒç»­ç›‘æ§ç›´åˆ°æ‰‹åŠ¨åœæ­¢

#### è¾“å‡ºæ•°æ®æ ¼å¼

CSVæ–‡ä»¶åŒ…å«ä»¥ä¸‹åˆ—ï¼š
- `timestamp`: Unixæ—¶é—´æˆ³
- `datetime`: å¯è¯»æ—¶é—´æ ¼å¼
- `gpu_X_power`: GPU Xçš„åŠŸè€—ï¼ˆWï¼‰
- `gpu_X_utilization`: GPU Xçš„åˆ©ç”¨ç‡ï¼ˆ%ï¼‰
- `gpu_X_temperature`: GPU Xçš„æ¸©åº¦ï¼ˆÂ°Cï¼‰
- `gpu_X_memory_used`: GPU Xçš„å·²ç”¨æ˜¾å­˜ï¼ˆMBï¼‰
- `gpu_X_memory_total`: GPU Xçš„æ€»æ˜¾å­˜ï¼ˆMBï¼‰
- `gpu_X_graphics_clock`: GPU Xçš„å›¾å½¢é¢‘ç‡ï¼ˆMHzï¼‰
- `gpu_X_memory_clock`: GPU Xçš„æ˜¾å­˜é¢‘ç‡ï¼ˆMHzï¼‰

### GPUåŠŸè€—æ•°æ®å¯è§†åŒ– (`plot_gpu_power.py`)

å°†ç›‘æ§æ•°æ®è½¬æ¢ä¸ºç›´è§‚çš„å›¾è¡¨ï¼Œæ”¯æŒå¤šç§å¯è§†åŒ–æ–¹å¼ã€‚

#### åŸºæœ¬ä½¿ç”¨

```bash
# ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
python3 plot_gpu_power.py gpu_power_data.csv

# æŒ‡å®šè¾“å‡ºç›®å½•
python3 plot_gpu_power.py gpu_power_data.csv --output-dir ./plots

# ä¸æ˜¾ç¤ºå›¾è¡¨ï¼Œåªä¿å­˜æ–‡ä»¶
python3 plot_gpu_power.py gpu_power_data.csv --no-show

# ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
python3 plot_gpu_power.py gpu_power_data.csv --report power_report.txt
```

#### ç”Ÿæˆçš„å›¾è¡¨

1. **GPUåŠŸè€—å˜åŒ–å›¾** (`gpu_power_consumption.png`)
   - æ¯ä¸ªGPUçš„åŠŸè€—æ—¶é—´åºåˆ—
   - åŒ…å«åˆ©ç”¨ç‡èƒŒæ™¯å¡«å……

2. **å¤šGPUåŠŸè€—å¯¹æ¯”å›¾** (`gpu_power_comparison.png`)
   - æ‰€æœ‰GPUåŠŸè€—æ›²çº¿å¯¹æ¯”
   - æ˜¾ç¤ºæ€»åŠŸè€—æ›²çº¿

3. **åˆ©ç”¨ç‡å’ŒåŠŸè€—å…³ç³»å›¾** (`gpu_utilization_vs_power.png`)
   - æ•£ç‚¹å›¾æ˜¾ç¤ºåˆ©ç”¨ç‡å’ŒåŠŸè€—çš„çº¿æ€§å…³ç³»
   - åŒ…å«è¶‹åŠ¿çº¿

4. **GPUæ¸©åº¦å˜åŒ–å›¾** (`gpu_temperature.png`)
   - æ‰€æœ‰GPUçš„æ¸©åº¦æ—¶é—´åºåˆ—

#### å‚æ•°è¯´æ˜

- `csv_file`: è¾“å…¥çš„CSVæ•°æ®æ–‡ä»¶è·¯å¾„
- `--output-dir`: å›¾è¡¨è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: ./plotsï¼‰
- `--no-show`: ä¸æ˜¾ç¤ºå›¾è¡¨ï¼Œåªä¿å­˜æ–‡ä»¶
- `--report`: ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Šæ–‡ä»¶

### å¿«é€Ÿå¯åŠ¨

```bash
# ä½¿ç”¨äº¤äº’å¼å¿«é€Ÿå¯åŠ¨è„šæœ¬
./quick_start.sh

# æˆ–è€…ç›´æ¥è¿è¡Œæµ‹è¯•éªŒè¯å·¥å…·
python3 test_gpu_monitor.py
```

### å®Œæ•´ä½¿ç”¨ç¤ºä¾‹

```bash
# 1. å¼€å§‹ç›‘æ§GPUåŠŸè€—ï¼ˆ60ç§’ï¼‰
python3 multi_gpu_monitor.py --duration 60 --output gpu_test.csv --json gpu_test.json

# 2. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
python3 plot_gpu_power.py gpu_test.csv --output-dir ./test_plots --report test_report.txt

# 3. æŸ¥çœ‹ç»“æœ
ls -la test_plots/
cat test_report.txt
```

### ä¾èµ–å®‰è£…

```bash
# å®‰è£…Pythonä¾èµ–
pip install pandas matplotlib numpy

# ç¡®ä¿nvidia-smiå¯ç”¨
nvidia-smi
```

### æ³¨æ„äº‹é¡¹

1. éœ€è¦NVIDIAé©±åŠ¨å’Œnvidia-smiå·¥å…·
2. ç¡®ä¿æŒ‡å®šçš„GPU IDå­˜åœ¨ä¸”å¯è®¿é—®
3. é«˜é¢‘ç‡ç›‘æ§ï¼ˆ100msï¼‰ä¼šäº§ç”Ÿå¤§é‡æ•°æ®ï¼Œæ³¨æ„ç£ç›˜ç©ºé—´
4. å›¾è¡¨ç”Ÿæˆéœ€è¦matplotlibï¼Œå»ºè®®åœ¨å›¾å½¢ç¯å¢ƒä¸­è¿è¡Œ

## ğŸ—ï¸ é¡¹ç›®æ¶æ„

### ä¼ ç»Ÿå•å®ä¾‹æ¶æ„
```
Client Request â†’ VLLM Server (Single Instance) â†’ Response
```

### åˆ†ç¦»å¼æ¶æ„
```
Client Request â†’ Proxy Server â†’ Prefill Instance (GPU 0) â†’ KV Transfer â†’ Decode Instance (GPU 1) â†’ Response
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
LLM-dvfs/
â”œâ”€â”€ gpu_monitor.py                    # GPU ç›‘æ§æ¨¡å—
â”œâ”€â”€ server/                           # VLLM æµ‹è¯•å¥—ä»¶
â”‚   â”œâ”€â”€ README.md                     # æµ‹è¯•å¥—ä»¶è¯´æ˜
â”‚   â”‚
â”‚   â”œâ”€â”€ traditional/                  # ä¼ ç»Ÿå•å®ä¾‹æµ‹è¯•
â”‚   â”‚   â”œâ”€â”€ start_vllm_server.sh      # å¯åŠ¨å•å®ä¾‹æœåŠ¡å™¨
â”‚   â”‚   â”œâ”€â”€ test_vllm_server.py       # å•å®ä¾‹æµ‹è¯•è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ run_server_test.sh        # å•å®ä¾‹æµ‹è¯•è¿è¡Œè„šæœ¬
â”‚   â”‚   â”œâ”€â”€ analyze_server_results.py # å•å®ä¾‹ç»“æœåˆ†æ
â”‚   â”‚   â”œâ”€â”€ README_vllm_server.md     # å•å®ä¾‹æµ‹è¯•è¯´æ˜
â”‚   â”‚   â””â”€â”€ vllm_server_results/      # å•å®ä¾‹æµ‹è¯•ç»“æœ
â”‚   â”‚
â”‚   â”œâ”€â”€ disaggregated/                # åˆ†ç¦»å¼æµ‹è¯•
â”‚   â”‚   â”œâ”€â”€ start_disaggregated_servers.sh    # å¯åŠ¨åˆ†ç¦»å¼æœåŠ¡å™¨
â”‚   â”‚   â”œâ”€â”€ disagg_prefill_proxy_server.py    # ä»£ç†æœåŠ¡å™¨
â”‚   â”‚   â”œâ”€â”€ test_disaggregated_performance.py # åˆ†ç¦»å¼æµ‹è¯•è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ run_disaggregated_test.sh         # åˆ†ç¦»å¼æµ‹è¯•è¿è¡Œè„šæœ¬
â”‚   â”‚   â”œâ”€â”€ compare_performance.py            # æ€§èƒ½å¯¹æ¯”åˆ†æ
â”‚   â”‚   â”œâ”€â”€ README_disaggregated.md           # åˆ†ç¦»å¼æµ‹è¯•è¯´æ˜
â”‚   â”‚   â””â”€â”€ disaggregated_results/            # åˆ†ç¦»å¼æµ‹è¯•ç»“æœ
â”‚   â”‚
â”‚   â””â”€â”€ reference/                    # å®˜æ–¹å‚è€ƒæ–‡ä»¶
â”‚       â””â”€â”€ disaggregated_prefill.sh          # å®˜æ–¹åˆ†ç¦»å¼ç¤ºä¾‹
â”‚
â””â”€â”€ README.md                         # é¡¹ç›®è¯´æ˜ï¼ˆæœ¬æ–‡ä»¶ï¼‰
```

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### GPU ç›‘æ§ (`gpu_monitor.py`)
- **å®æ—¶ç›‘æ§**: GPU åŠŸè€—ã€é¢‘ç‡ã€åˆ©ç”¨ç‡ã€æ¸©åº¦
- **æ•°æ®ä¿å­˜**: æ”¯æŒ JSON æ ¼å¼ä¿å­˜å’Œç»Ÿè®¡åˆ†æ
- **å¯é…ç½®**: é‡‡æ ·é—´éš”ã€ç›‘æ§ GPU ç­‰å‚æ•°
- **å¤š GPU**: æ”¯æŒåŒæ—¶ç›‘æ§å¤šä¸ª GPU

### ä¼ ç»Ÿå•å®ä¾‹æµ‹è¯•
- **æ¨¡æ‹Ÿåˆ†ç¦»**: é€šè¿‡ `max_tokens` å‚æ•°æ¨¡æ‹Ÿ prefill å’Œ decode
- **åŠŸè€—åˆ†æ**: è¯¦ç»†çš„ GPU åŠŸè€—å’Œæ€§èƒ½åˆ†æ
- **ç»“æœå¯¹æ¯”**: ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨å’ŒæŠ¥å‘Š

### åˆ†ç¦»å¼æµ‹è¯•
- **çœŸæ­£åˆ†ç¦»**: Prefill å’Œ Decode è¿è¡Œåœ¨ä¸åŒ GPU ä¸Š
- **KV ä¼ è¾“**: é€šè¿‡ P2P NCCL è¿›è¡Œé«˜é€Ÿç¼“å­˜ä¼ è¾“
- **ç²¾ç¡®æŒ‡æ ‡**: TTFTã€TBTã€E2E Latency æµ‹é‡
- **åŒ GPU ç›‘æ§**: åŒæ—¶ç›‘æ§ä¸¤ä¸ª GPU çš„å®æ—¶çŠ¶æ€

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šä¼ ç»Ÿå•å®ä¾‹æµ‹è¯•

```bash
# 1. å¯åŠ¨å•å®ä¾‹æœåŠ¡å™¨
cd server/traditional
./start_vllm_server.sh

# 2. è¿è¡Œæµ‹è¯•ï¼ˆæ–°ç»ˆç«¯ï¼‰
cd server/traditional
./run_server_test.sh

# 3. åˆ†æç»“æœ
python3 analyze_server_results.py
```

### æ–¹å¼äºŒï¼šåˆ†ç¦»å¼æµ‹è¯•

```bash
# 1. å¯åŠ¨åˆ†ç¦»å¼æœåŠ¡å™¨ï¼ˆéœ€è¦ 2 ä¸ª GPUï¼‰
cd server/disaggregated
./start_disaggregated_servers.sh

# 2. è¿è¡Œåˆ†ç¦»å¼æµ‹è¯•ï¼ˆæ–°ç»ˆç«¯ï¼‰
cd server/disaggregated
./run_disaggregated_test.sh

# 3. å¯¹æ¯”åˆ†æ
python3 compare_performance.py
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### ä¼ ç»Ÿæ–¹å¼æŒ‡æ ‡
- **Prefill æ—¶é—´**: å¤„ç†è¾“å…¥æç¤ºè¯çš„æ—¶é—´
- **Decode æ—¶é—´**: ç”Ÿæˆè¾“å‡º tokens çš„æ—¶é—´
- **æ€»æ—¶é—´**: å®Œæ•´çš„æ¨ç†æ—¶é—´
- **åŠŸè€—ç»Ÿè®¡**: å¹³å‡/æœ€å¤§åŠŸè€—ã€èƒ½è€—

### åˆ†ç¦»å¼æŒ‡æ ‡
- **TTFT (Time to First Token)**: é¦– token æ—¶é—´
- **TBT (Time Between Tokens)**: token é—´æ—¶é—´
- **E2E Latency**: ç«¯åˆ°ç«¯å»¶è¿Ÿ
- **KV ä¼ è¾“æ—¶é—´**: ç¼“å­˜ä¼ è¾“è€—æ—¶
- **åŒ GPU åŠŸè€—**: åˆ†åˆ«ç›‘æ§ä¸¤ä¸ª GPU

## ğŸ“ˆ è¾“å‡ºç»“æœ

### ä¼ ç»Ÿå•å®ä¾‹ç»“æœ
- `server/traditional/vllm_server_results/prefill_results.json` - Prefill é˜¶æ®µç»“æœ
- `server/traditional/vllm_server_results/decode_results.json` - Decode é˜¶æ®µç»“æœ
- `server/traditional/vllm_server_results/vllm_server_comparison.png` - æ€§èƒ½å¯¹æ¯”å›¾è¡¨

### åˆ†ç¦»å¼ç»“æœ
- `server/disaggregated/disaggregated_results/disaggregated_results.json` - å®Œæ•´æµ‹è¯•ç»“æœ
- `server/disaggregated/disaggregated_results/prefill_gpu_data.json` - Prefill GPU ç›‘æ§æ•°æ®
- `server/disaggregated/disaggregated_results/decode_gpu_data.json` - Decode GPU ç›‘æ§æ•°æ®
- `server/disaggregated/disaggregated_results/disaggregated_performance_analysis.png` - è¯¦ç»†æ€§èƒ½åˆ†æå›¾è¡¨

### å¯¹æ¯”åˆ†æç»“æœ
- `server/disaggregated/performance_comparison.png` - ä¼ ç»Ÿ vs åˆ†ç¦»å¼æ€§èƒ½å¯¹æ¯”å›¾

## ğŸ”§ æŠ€æœ¯ç‰¹ç‚¹

### åŠŸè€—ç›‘æ§
- **é‡‡æ ·é¢‘ç‡**: 100ms é«˜ç²¾åº¦é‡‡æ ·
- **ç›‘æ§æŒ‡æ ‡**: åŠŸè€—ã€é¢‘ç‡ã€åˆ©ç”¨ç‡ã€æ¸©åº¦
- **æ•°æ®æº**: ç›´æ¥ä½¿ç”¨ nvidia-smi ç¡¬ä»¶ä¼ æ„Ÿå™¨
- **å¯è§†åŒ–**: å®æ—¶åŠŸè€—å˜åŒ–æ›²çº¿å›¾

### åˆ†ç¦»å¼æ¶æ„
- **ç‰©ç†åˆ†ç¦»**: Prefill å’Œ Decode è¿è¡Œåœ¨ä¸åŒ GPU
- **KV ä¼ è¾“**: P2P NCCL é«˜é€Ÿç¼“å­˜ä¼ è¾“
- **ä»£ç†æœåŠ¡**: è‡ªåŠ¨å¤„ç†è¯·æ±‚è½¬å‘å’Œç»“æœåˆå¹¶
- **èµ„æºéš”ç¦»**: ç‹¬ç«‹çš„ GPU èµ„æºç®¡ç†

### æ€§èƒ½åˆ†æ
- **æ—¶é—´ç²¾åº¦**: å¾®ç§’çº§æ—¶é—´æµ‹é‡
- **å¤šç»´åº¦**: æ—¶é—´ã€åŠŸè€—ã€é¢‘ç‡ã€åˆ©ç”¨ç‡
- **å¯¹æ¯”åˆ†æ**: ä¼ ç»Ÿ vs åˆ†ç¦»å¼æ¶æ„å¯¹æ¯”
- **å¯è§†åŒ–**: ä¸°å¯Œçš„å›¾è¡¨å’Œç»Ÿè®¡åˆ†æ

## ğŸ“‹ ä¾èµ–è¦æ±‚

### åŸºç¡€ä¾èµ–
- Python 3.8+
- VLLM 0.10.2+
- PyTorch
- matplotlib
- requests
- numpy

### åˆ†ç¦»å¼æµ‹è¯•é¢å¤–ä¾èµ–
- Quart (ä»£ç†æœåŠ¡å™¨)
- aiohttp (å¼‚æ­¥ HTTP å®¢æˆ·ç«¯)
- è‡³å°‘ 2 ä¸ª GPU
- P2P é€šä¿¡æ”¯æŒ (NVLink æˆ– PCIe)

### ç³»ç»Ÿè¦æ±‚
- nvidia-smi (GPU ç›‘æ§)
- CUDA é©±åŠ¨
- è¶³å¤Ÿçš„ GPU å†…å­˜

## âš ï¸ æ³¨æ„äº‹é¡¹

### ç¡¬ä»¶è¦æ±‚
- **ä¼ ç»Ÿæµ‹è¯•**: 1 ä¸ª GPUï¼Œ8GB+ æ˜¾å­˜
- **åˆ†ç¦»å¼æµ‹è¯•**: 2 ä¸ª GPUï¼Œæ¯ä¸ª 8GB+ æ˜¾å­˜
- **P2P é€šä¿¡**: GPU é—´éœ€è¦æ”¯æŒ P2P é€šä¿¡

### è½¯ä»¶é…ç½®
- ç¡®ä¿ VLLM ç‰ˆæœ¬å…¼å®¹
- æ£€æŸ¥ GPU é©±åŠ¨å’Œ CUDA ç‰ˆæœ¬
- éªŒè¯æ¨¡å‹è·¯å¾„å’Œæƒé™

### æ€§èƒ½ä¼˜åŒ–
- æµ‹è¯•æœŸé—´å…³é—­å…¶ä»– GPU å¯†é›†å‹åº”ç”¨
- æ ¹æ®ç¡¬ä»¶è°ƒæ•´ GPU å†…å­˜åˆ©ç”¨ç‡
- ä¼˜åŒ– KV ä¼ è¾“è·¯å¾„ (åŒ NVLink ç»„)

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜
1. **CUDA å¤šè¿›ç¨‹é”™è¯¯**: å·²é€šè¿‡è®¾ç½® `spawn` æ¨¡å¼è§£å†³
2. **ç«¯å£å†²çª**: æ£€æŸ¥ç«¯å£å ç”¨æƒ…å†µ
3. **GPU å†…å­˜ä¸è¶³**: è°ƒæ•´ `gpu_memory_utilization` å‚æ•°
4. **KV ä¼ è¾“å¤±è´¥**: æ£€æŸ¥ GPU é—´ P2P è¿æ¥

### è°ƒè¯•æ–¹æ³•
- æŸ¥çœ‹æœåŠ¡å™¨å¯åŠ¨æ—¥å¿—
- æ£€æŸ¥ GPU çŠ¶æ€: `nvidia-smi`
- éªŒè¯ç½‘ç»œè¿æ¥: `curl localhost:8000/health`
- æŸ¥çœ‹ä»£ç†æœåŠ¡å™¨æ—¥å¿—

## ğŸ“š æ‰©å±•åŠŸèƒ½

### æ‰¹é‡æµ‹è¯•
- æ”¯æŒå¹¶å‘è¯·æ±‚æµ‹è¯•
- æ‰¹é‡æ€§èƒ½åˆ†æ
- è´Ÿè½½å‡è¡¡æµ‹è¯•

### ä¸åŒæ¨¡å‹å¯¹æ¯”
- æ”¯æŒå¤šç§æ¨¡å‹æµ‹è¯•
- æ¨¡å‹æ€§èƒ½å¯¹æ¯”åˆ†æ
- é…ç½®å‚æ•°ä¼˜åŒ–

### è·¨èŠ‚ç‚¹éƒ¨ç½²
- æ”¯æŒè·¨æœºå™¨åˆ†ç¦»å¼éƒ¨ç½²
- ç½‘ç»œå¸¦å®½ä¼˜åŒ–
- åˆ†å¸ƒå¼æ€§èƒ½åˆ†æ

## ğŸ¦™ Llama.cpp è¿è¡ŒæŒ‡ä»¤

### RTX 4080 16GBæ˜¾å­˜ä¼˜åŒ–é…ç½®

#### åŸºç¡€è¿è¡ŒæŒ‡ä»¤ï¼š
```bash
~/offload/llama.cpp/build/bin/llama-cli \
  -m /share-data/wzk-1/model/DeepSeek-R1-Distill-Qwen-32B/model.gguf \
  -ngl 35 \
  -c 4096 \
  -b 512 \
  -t 8 \
  --mlock \
  --no-mmap
```

#### è¯¦ç»†å‚æ•°è¯´æ˜ï¼š

**æ˜¾å­˜ä¼˜åŒ–å‚æ•°ï¼š**
- `-ngl 50`: å°†50å±‚åŠ è½½åˆ°GPUï¼ˆçº¦å ç”¨13-15GBæ˜¾å­˜ï¼Œä¸ºç³»ç»Ÿé¢„ç•™1-3GBï¼‰
- `-c 4096`: ä¸Šä¸‹æ–‡é•¿åº¦4096 tokens
- `-b 512`: æ‰¹å¤„ç†å¤§å°512
- `--mlock`: é”å®šå†…å­˜ï¼Œé˜²æ­¢äº¤æ¢åˆ°ç£ç›˜
- `--no-mmap`: ç¦ç”¨å†…å­˜æ˜ å°„ï¼Œå‡å°‘å†…å­˜ç¢ç‰‡

#### æœ€å¤§åŒ–æ˜¾å­˜åˆ©ç”¨ç‰ˆæœ¬ï¼ˆæ¨èï¼‰ï¼š
```bash
~/offload/llama.cpp/build/bin/llama-cli \
  -m /share-data/wzk-1/model/DeepSeek-R1-Distill-Qwen-32B/model.gguf \
  -ngl 50 \
  -c 16384 \
  -b 2048 \
  -t 16 \
  --mlock \
  --no-mmap
```
### å»ºè®®çš„æµ‹è¯•æµç¨‹ï¼š

1. **å…ˆæµ‹è¯•ä¿å®ˆé…ç½®**ï¼Œç¡®ä¿æ¨¡å‹èƒ½æ­£å¸¸åŠ è½½
2. **é€æ­¥å¢åŠ `-ngl`å€¼**ï¼ˆ30â†’40â†’50ï¼‰ï¼Œç›‘æ§æ˜¾å­˜ä½¿ç”¨
3. **ä½¿ç”¨`nvidia-smi`ç›‘æ§æ˜¾å­˜å ç”¨**ï¼š
   ```bash
   watch -n 1 nvidia-smi
   ```

### æ˜¾å­˜ä½¿ç”¨ä¼°ç®—ï¼š
- **35å±‚**: ~11-13GBæ˜¾å­˜  
- **40å±‚**: ~13-15GBæ˜¾å­˜
- **50å±‚**: ~15-18GBæ˜¾å­˜ï¼ˆæ¥è¿‘æé™ï¼‰

### æ ¹æ®æ‚¨çš„å®é™…æ˜¾å­˜ä½¿ç”¨æƒ…å†µï¼š
- **å½“å‰ä½¿ç”¨**: 8-10GBæ˜¾å­˜
- **å¯ç”¨ç©ºé—´**: 6-8GBæ˜¾å­˜
- **å»ºè®®é…ç½®**: `-ngl 50` å¯ä»¥å……åˆ†åˆ©ç”¨å‰©ä½™æ˜¾å­˜
- **æé™æµ‹è¯•**: `-ngl 60` å¯ä»¥æµ‹è¯•æ˜¾å­˜ä¸Šé™

**æ¨èä»`-ngl 50`å¼€å§‹æµ‹è¯•**ï¼Œå……åˆ†åˆ©ç”¨æ‚¨çš„16GBæ˜¾å­˜ã€‚

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å¼€æºã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Request æ¥æ”¹è¿›é¡¹ç›®ï¼