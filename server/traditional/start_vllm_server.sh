#!/bin/bash

# VLLM æœåŠ¡å™¨å¯åŠ¨è„šæœ¬
# ä½¿ç”¨æ‚¨æä¾›çš„å‚æ•°é…ç½®

set -e

echo "ğŸš€ å¯åŠ¨ VLLM ä¼ ç»ŸæœåŠ¡å™¨..."
echo "æ¨¡å‹è·¯å¾„: /share-data/wzk-1/model/DeepSeek-R1-Distill-Qwen-32B"
echo "ç«¯å£: 8000"
echo "é…ç½®å‚æ•°:"
echo "  - CPU offload: 56GB"
echo "  - å¼ºåˆ¶ eager æ¨¡å¼"
echo "  - GPU å†…å­˜åˆ©ç”¨ç‡: 80% (é™ä½ä»¥æé«˜ç¨³å®šæ€§)"
echo "  - æœ€å¤§æ¨¡å‹é•¿åº¦: 8192 (æ”¯æŒé•¿è¾“å…¥BBHæµ‹è¯•)"
echo "  - ä¿¡ä»»è¿œç¨‹ä»£ç "
echo "  - æ‰¹å¤„ç†ä¼˜åŒ–: æ”¯æŒé•¿åºåˆ—"
echo "  - æœ€å¤§å¹¶å‘åºåˆ—æ•°: ${MAX_SEQS:-8}"
echo ""

# é¢„æ£€æŸ¥å‡½æ•°
precheck() {
    echo "ğŸ” æ‰§è¡Œé¢„æ£€æŸ¥..."
    
    # æ£€æŸ¥æ¨¡å‹è·¯å¾„
    if [ ! -d "/share-data/wzk-1/model/DeepSeek-R1-Distill-Qwen-32B" ]; then
        echo "âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: /share-data/wzk-1/model/DeepSeek-R1-Distill-Qwen-32B"
        exit 1
    fi
    
    # æ£€æŸ¥GPUçŠ¶æ€
    if ! nvidia-smi &> /dev/null; then
        echo "âŒ nvidia-smi ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥CUDAç¯å¢ƒ"
        exit 1
    fi
    
    # æ£€æŸ¥ç«¯å£å ç”¨
    if lsof -Pi :8000 -sTCP:LISTEN -t >/dev/null 2>&1; then 
        echo "âš ï¸  ç«¯å£ 8000 å·²è¢«å ç”¨ï¼Œå°è¯•æ¸…ç†..."
        lsof -ti:8000 | xargs kill -9 2>/dev/null || true
        sleep 2
    fi
    
    echo "âœ… é¢„æ£€æŸ¥å®Œæˆ"
}

# æ¸…ç†å‡½æ•°
cleanup() {
    echo "ğŸ§¹ æ¸…ç†æœåŠ¡å™¨è¿›ç¨‹..."
    pgrep -f "vllm serve" | xargs kill -9 2>/dev/null || true
    echo "âœ… æ¸…ç†å®Œæˆ"
    exit 0
}

# æ•è· Ctrl+C
trap cleanup INT

# æ‰§è¡Œé¢„æ£€æŸ¥
precheck

# è®¾ç½®ç¯å¢ƒå˜é‡é¿å…å¤šè¿›ç¨‹é—®é¢˜
export CUDA_VISIBLE_DEVICES=0
export VLLM_USE_MODELSCOPE=False
export VLLM_WORKER_MULTIPROC_METHOD=spawn
export VLLM_ENGINE_MULTIPROC_METHOD=spawn
export CUDA_LAUNCH_BLOCKING=1
export LD_LIBRARY_PATH="/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH"
export TRITON_CACHE_DIR="/tmp/triton_cache"

echo "ğŸ”§ å¯åŠ¨ VLLM æœåŠ¡å™¨..."

# å¯åŠ¨ VLLM æœåŠ¡å™¨
vllm serve /share-data/wzk-1/model/deepseek-v2-lite \
    --host 0.0.0.0 \
    --port 8000 \
    --cpu-offload-gb 20 \
    --enforce-eager \
    --gpu-memory-utilization 0.95 \
    --trust-remote-code \
    --max-model-len 8192 \
    --max-num-batched-tokens 32768 \
    --max-num-seqs ${MAX_SEQS:-8} \
    --disable-log-stats
